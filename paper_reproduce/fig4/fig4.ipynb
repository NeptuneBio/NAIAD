{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from naiad import NAIAD, load_naiad_data, ActiveLearner, ActiveLearnerReplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "pd.set_option(\"mode.copy_on_write\", True)\n",
    "\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = 'norman'\n",
    "data_map = {'norman': '../../data/norman/norman_gamma.csv',\n",
    "            'simpson': '../../data/simpson/simpson_gamma.csv',\n",
    "            'horlbeck_jurkat': '../../data/horlbeck/horlbeck_jurkat_gamma.csv',\n",
    "            'horlbeck_k562': '../../data/horlbeck/horlbeck_k562_gamma.csv'}\n",
    "data_file = data_map[data_source]\n",
    "\n",
    "os.mkdir('./results') if not os.path.exists('./results') else None\n",
    "\n",
    "time_label = datetime.now().strftime(r'%Y-%m-%d-%H-%M-%S')\n",
    "result_dir = os.path.join('./results/', f'{data_source}_{time_label}')\n",
    "os.mkdir(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_mins = {\n",
    "    'mean': True,           # since strong cell viability scores are negative, we want to minimize them\n",
    "    'std': False,           # we want to pick points with maximum standard deviation\n",
    "    'residual+std': False   # and also pick points with maximum residual+std\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_source == 'norman':\n",
    "    model_args = [\n",
    "        {'model_type': 'both', 'd_embed': 2, 'd_pheno_hid': 64, 'p_dropout': 0.1}, \n",
    "        {'model_type': 'both', 'd_embed': 4, 'd_pheno_hid': 64, 'p_dropout': 0.1},\n",
    "        {'model_type': 'both', 'd_embed': 4, 'd_pheno_hid': 64, 'p_dropout': 0.1},\n",
    "        {'model_type': 'both', 'd_embed': 8, 'd_pheno_hid': 64, 'p_dropout': 0.1},\n",
    "        {'model_type': 'both', 'd_embed': 16, 'd_pheno_hid': 64, 'p_dropout': 0.1}\n",
    "    ]\n",
    "    n_sample = [100, 200, 300, 400, 500]\n",
    "elif data_source in ['simpson', 'horlbeck_jurkat', 'horlbeck_k562']:\n",
    "    model_args = [\n",
    "        {'model_type': 'both', 'd_embed': 2, 'd_pheno_hid': 256, 'p_dropout': 0.1}, \n",
    "        {'model_type': 'both', 'd_embed': 8, 'd_pheno_hid': 256, 'p_dropout': 0.1},\n",
    "        {'model_type': 'both', 'd_embed': 8, 'd_pheno_hid': 256, 'p_dropout': 0.1},\n",
    "        {'model_type': 'both', 'd_embed': 16, 'd_pheno_hid': 256, 'p_dropout': 0.1},\n",
    "        {'model_type': 'both', 'd_embed': 32, 'd_pheno_hid': 256, 'p_dropout': 0.1}\n",
    "    ]\n",
    "    n_sample = [500, 1000, 1500, 2000, 2500]\n",
    "\n",
    "if data_source == 'norman':\n",
    "    n_epoch = 200\n",
    "    batch_size = 4096\n",
    "elif data_source in ['simpson', 'horlbeck_jurkat', 'horlbeck_k562']:\n",
    "    n_epoch = 100\n",
    "    batch_size = 4096\n",
    "        \n",
    "model_optimizer_settings = {'pheno_lr': 1e-2, 'embed_lr': 1e-2, 'weight_decay': 0}\n",
    "test_frac = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_naiad_data(data_file)\n",
    "active_learner = ActiveLearner(\n",
    "    n_round = 5, \n",
    "    data = data, \n",
    "    model = NAIAD, \n",
    "    model_args = model_args,\n",
    "    model_optimizer_settings = model_optimizer_settings,\n",
    "    n_ensemble = 5,\n",
    "    n_epoch = n_epoch,\n",
    "    n_sample = n_sample, \n",
    "    test_frac = test_frac, \n",
    "    early_stop = False,\n",
    "    device = device,\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "active_learner_reps = ActiveLearnerReplicates(\n",
    "    n_rep = 5, \n",
    "    overall_seed = 0, \n",
    "    active_learner = active_learner, \n",
    "    save_dir = result_dir, \n",
    "    save_prefix = data_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_learner_reps.set_method('mean', True)\n",
    "results = active_learner_reps.run_replicates(parallel=True)\n",
    "aggregated_results = active_learner_reps.aggregate_replicate_metrics(return_value=True)\n",
    "active_learner_reps.save_aggregated_results(data_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_learner_reps.set_method('std', False)\n",
    "active_learner_reps.run_replicates(parallel=True)\n",
    "active_learner_reps.aggregate_replicate_metrics(return_value=False)\n",
    "active_learner_reps.save_aggregated_results(data_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Residual+Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_learner_reps.set_method('residual+std', False)\n",
    "active_learner_reps.run_replicates(parallel=True)\n",
    "active_learner_reps.aggregate_replicate_metrics(return_value=False)\n",
    "active_learner_reps.save_aggregated_results(data_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_learner_reps.save_aggregated_results(data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_learner_reps.plot_aggregated_results(\n",
    "    metrics = ['mse', 'tpr'], \n",
    "    splits = 'overall', \n",
    "    methods = ['mean', 'std', 'residual+std'], \n",
    "    orientation = 'horizontal'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naiad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
