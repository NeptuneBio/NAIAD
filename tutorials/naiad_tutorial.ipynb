{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAIAD Tutorial\n",
    "\n",
    "The purpose of this tutorial is to provide a tutorial about the essential functions to train and evaluate NAIAD. We introduce:\n",
    "1) NAIAD model and workflow for training a model based on genetic perturbation data and predicting new perturbations\n",
    "2) Evaluation of NAIAD model performane with the increase of training data\n",
    "\n",
    "We will use the [Norman2019](https://www.science.org/doi/10.1126/science.aax4438) combinatorial perturbation dataset, which contains cell viability measurements for CRISPRa pairwise genetic perturbations of ~120 genes.\n",
    "\n",
    "Besides the Norman2019 dataset, you can also try out these models on the [Simpson2023](https://www.biorxiv.org/content/10.1101/2023.08.19.553986v1) and [Horlbeck2018](https://www.cell.com/cell/fulltext/S0092-8674\\(18\\)30735-9) datasets, present within the `./data` subfolder of this `tutorials` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from naiad import load_naiad_data, NAIAD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some configuration settings for the notebook\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "pd.set_option(\"mode.copy_on_write\", True)\n",
    "\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAIAD model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide path to relevant data directories\n",
    "data_file = './data/norman_gamma.csv'\n",
    "result_dir = './results/naiad'\n",
    "\n",
    "# parameters for initializing and running model\n",
    "device = (\n",
    "    'cuda' if torch.cuda.is_available() else\n",
    "    'mps' if torch.backends.mps.is_available() else\n",
    "    'cpu'\n",
    ")\n",
    "seed = 42\n",
    "n_epoch = 100\n",
    "\n",
    "# set up how to split data\n",
    "n_train = 500 \n",
    "n_val = 1000\n",
    "n_test = 1000\n",
    "\n",
    "emb_model = 'transformer-cls'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reloading module naiad\n",
      "reloading module naiad.models\n",
      "reloading module naiad.naiad\n"
     ]
    }
   ],
   "source": [
    "from naiad.utils import reload_module\n",
    "reload_module(\"naiad\")\n",
    "reload_module(\"naiad.models\")\n",
    "reload_module(\"naiad.naiad\")\n",
    "from naiad import load_naiad_data, NAIAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load and split data\n",
    "naiad_data = load_naiad_data(data_file)\n",
    "#naiad_data['rank'] = np.argsort(np.argsort(naiad_data['comb_score'])) + 1\n",
    "naiad_model = NAIAD(naiad_data, n_train=n_train, n_val=n_val, n_test=n_test )\n",
    "naiad_model.set_seed(seed=seed)\n",
    "naiad_model.prepare_data()\n",
    "\n",
    "# initialize model and prepare trainer\n",
    "naiad_model.initialize_model(device=device, model_args={'embed_model': emb_model})\n",
    "naiad_model.setup_trainer(n_epoch=n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model training\n",
    "naiad_model.train_model(ranking_model = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions using the best model based on the validation loss\n",
    "naiad_model.generate_preds(use_best=True)\n",
    "naiad_model.generate_attentions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "fig = naiad_model.plot_loss_curves(log=True)\n",
    "fig = naiad_model.plot_preds('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract relevant data from object\n",
    "model = naiad_model.model                 # final model after training\n",
    "best_model = naiad_model.best_model       # best model after training based on minimum val loss\n",
    "preds = naiad_model.preds                 # predictions from best model on all data splits\n",
    "losses = naiad_model.training_metrics     # train / val loss during training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation performance of NAIAD model with the increase of training data\n",
    "Here we demonstrate how to train the model by one replicates and by ensembled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_set = range(100, 3000, 200)\n",
    "n_val = 1000\n",
    "n_test = 1000\n",
    "n_epoch = 100\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "test_loss = []\n",
    "\n",
    "\n",
    "for n_train in tqdm.tqdm(n_train_set):\n",
    "    naiad_model = NAIAD(naiad_data, n_train=n_train, n_val=n_val, n_test=n_test)\n",
    "    naiad_model.set_seed(seed=seed)\n",
    "    naiad_model.prepare_data()\n",
    "\n",
    "    naiad_model.initialize_model(device=device, model_args={'embed_model': emb_model})\n",
    "    naiad_model.setup_trainer(n_epoch=n_epoch)\n",
    "    naiad_model.train_model()\n",
    "    \n",
    "    losses = naiad_model.training_metrics  \n",
    "    losses['val_loss'][0:50] = [1]*50\n",
    "    loss_index = np.argmin(losses['val_loss'])\n",
    "    train_loss.append( losses['train_loss'][loss_index])\n",
    "    val_loss.append( losses['val_loss'][loss_index])\n",
    "    test_loss.append( losses['test_loss'][loss_index])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=n_train_set, y=val_loss, label='val_loss')\n",
    "sns.lineplot(x=n_train_set,y=test_loss, label='test_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model with replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from naiad.utils import EnsembleModels\n",
    "import tqdm \n",
    "def run_model_replicates(n_ensemble,  emb_model_name):\n",
    "    \n",
    "    \n",
    "    n_train_set = range(100, 3000, 200)\n",
    "    n_val = 1000\n",
    "    n_test = 1000\n",
    "    n_epoch = 100\n",
    "    loss_metric = pd.DataFrame(columns=['val_loss_mean', 'test_loss_mean', 'val_loss_std', 'test_loss_std'], index=n_train_set, dtype=float)\n",
    "\n",
    "\n",
    "    \n",
    "    for n_train in tqdm.tqdm(n_train_set):\n",
    "        naiad_model = NAIAD(naiad_data, n_train=n_train, n_val=n_val, n_test=n_test )\n",
    "        _, ensemble_loss = EnsembleModels(model=naiad_model, n_ensemble=n_ensemble, n_epoch = n_epoch, device=device, model_args={'embed_model': emb_model_name})\n",
    "\n",
    "\n",
    "        ensemble_loss_index = list()\n",
    "        for loss_i in ensemble_loss:\n",
    "            loss_i['val_loss'][0:50] = [1]*50\n",
    "            ensemble_loss_index.append(np.argmin(loss_i['val_loss']))\n",
    "\n",
    "        ensemble_val_loss = np.array([ensemble_loss[i]['val_loss'][ensemble_loss_index[i]] for i in range(len(ensemble_loss)) ])\n",
    "        ensemble_test_loss = np.array([ensemble_loss[i]['test_loss'][ensemble_loss_index[i]] for i in range(len(ensemble_loss)) ])\n",
    "        \n",
    "        loss_metric.loc[n_train] = [np.mean( ensemble_val_loss), np.mean(ensemble_test_loss),\\\n",
    "                                    np.std(ensemble_val_loss),  np.std(ensemble_test_loss)]\n",
    "    return loss_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_mlp = run_model_replicates(n_ensemble=5, emb_model_name='MLP')\n",
    "loss_multihead = run_model_replicates(n_ensemble=5, emb_model_name='multihead')\n",
    "loss_transformer  = run_model_replicates(n_ensemble=5, emb_model_name='transformer')\n",
    "loss_transformer_cls = run_model_replicates(n_ensemble=5, emb_model_name='transformer-cls')\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(np.array(n_train_set), np.log(loss_metric['val_loss_mean']), label='Val loss mean', linestyle='-')\n",
    "plt.plot(n_train_set, np.log(loss_metric['test_loss_mean']), label='Test loss mean',   linestyle='-')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation and Test Loss with the increase of training data' + ' (' + emb_model + ')')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naiad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
